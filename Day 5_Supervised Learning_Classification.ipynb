{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding (EDA technique)\n",
    "\n",
    "Variables can be classified as\n",
    "\n",
    "1. Quantitative - discrete, continuous\n",
    "2. Qualitative - nominal, ordinal, binomial i.e. Categorical variables\n",
    "\n",
    "Machine Learning only works with numbers so you need to convert categorical variables to numbers using ENCODING\n",
    "\n",
    "2 Types of Encoding\n",
    "1. One hot encoding\n",
    "2. Label encoding - for catogorical target variables\n",
    "\n",
    "__One hot encoding__ - One is used to encode all the features.\n",
    "\n",
    "The column to be encoded will be split into the number of classes in that column (to be encoded) and the particular class will be represented as a 1 when it occurs while other split column on the same row will be 0.\n",
    "\n",
    "Syntax for One hot encoding:\n",
    "\n",
    "pd.get_dummes(dfname['columnname'])  i.e. pd.get_dummies(thecolumntobeencoded)\n",
    "\n",
    "__Label Encoding__- Used for categorical target variables\n",
    "\n",
    "It does not result in additional columns but instead, maps a number to each of the label.\n",
    "\n",
    "So while one hot encoding will result in additional columns, the label encoding will retain the single column\n",
    "\n",
    "Syntax for Label encoder\n",
    "- import it from the sklearn preprocessing package\n",
    "- initialize the label enoder and pass the target column to be encoded in the fit_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a supervised machine learning approach, used when the target/dependent variable (y) is of categorical type.\n",
    "\n",
    "Example: Tall/Short/Medium, Yes/No, Grades of students, sick/healthy\n",
    "\n",
    "#### Algorithms\n",
    "1. Logistic Regression\n",
    "2. K Nearest Neighbors\n",
    "3. Decision Trees\n",
    "4. Support Vector Machines\n",
    "5. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression\n",
    "\n",
    "It's widely used to predict binary outcomes for a given set of independent variables. It's based on linear regression/straight line equation but log was applied to turn the line shape to an 'S' shape.\n",
    "\n",
    "The dependent variabe outcome is discrete i.e y=0 or y=1\n",
    "\n",
    "It calculates the probablity of the observation belonging to one of the classes i.e. 1 or 0, pass or fail, sick or healthy\n",
    "\n",
    "e.g. if the probablity of student passing an exam is 0.4 --> Fail\n",
    "1 - 0.4 = 0.6 --> Pass\n",
    "A threshold is set and above the threshold --> 1 or yes, below the threshold --> 0 or no\n",
    "\n",
    "**It can be used for target variable with 2 - 3 classes but doesn't work well beyond that**\n",
    "\n",
    "The probability distribution of output is restricted to 1 or 0. This is called __sigmoid probability__/logistic funtion/S curve\n",
    "\n",
    "#### Application:\n",
    "- Loan approval\n",
    "- Spam filtering\n",
    "- Customer segment\n",
    "- Exam results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See further down in this notebook for logistic regression code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K Nearest Neighbors\n",
    "\n",
    "1. Determine k value - when your target variable has even number of classes, use an odd numbered k value and when the target variable has odd number of classes, use even number k value. i.e. if you have 3 classes, use k=4\n",
    "2. The distance between the new data point and all the other datapoints is computed. There are many types of distance cals e.g. Euclidean, \n",
    "3. Distances are ranked in acsending order. The closest neighbors will be chosen based on the k value\n",
    "4. Based on majority class lable, the label for the new data point is assigned.\n",
    "\n",
    "k value is a hyperparameter so you need to try different values to see which value gives the best result. __Don't choose k value higer than 15 or 20__ to avoid increasing your prediction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import inbuilt dataset from sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the keys for the dataset\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the column names\n",
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the target/dependent variable column\n",
    "iris_df['class'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "class                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize the target variable\n",
    "\n",
    "This is important as you need to ensure that all the classes are equal to avoid bias towards any of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x295362bed08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_df['class'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X = iris_df.drop('class', axis=1)\n",
    "y = iris_df['class']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 4)\n",
      "(45, 4)\n",
      "(105,)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Build Model\n",
    "\n",
    "The target variable has 3 classes so we will start with k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the classifier object \n",
    "knn = KNeighborsClassifier(n_neighbors=4)  # n_neighbors is the k value=4\n",
    "\n",
    "# fit the model on the data. Since it' supervised learning, you pass both the X and y train data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Evaluate the model prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test data in KNN model is:\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy score for test data in KNN model is:')\n",
    "print(metrics.accuracy_score(y_test, y_test_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is __93.33%__ accurate on the testing data. To ensure the model is not overfitting, we will check the training data accuracy also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Quality Check\n",
    "\n",
    "1. Compare train and test data accuracy scores\n",
    "2. __Confusion matrix__ - tells us how well our model classified the data point. It is used for a 2 class classification problem\n",
    "\n",
    "#### 1. Compare train and test data accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for train data in KNN model is:\n",
      "0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "# training data accuracy\n",
    "y_train_knn = knn.predict(X_train)\n",
    "\n",
    "print('Accuracy score for train data in KNN model is:')\n",
    "print(metrics.accuracy_score(y_train, y_train_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train accuracy score is 95.23% which is about the train accuracy so this is __an appropriate model__. Not over fitted or under fitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "                     cancer | No cancer  - predicted value\n",
    "    Actual value     10(TP) | 20(FN)  - FN is a Type II error (more harmful/costly)\n",
    "                     30(FP) | 40(TN)  - FP is a Type I error\n",
    "        \n",
    "Baed on the values in the confusion matrix, we have 4 different metrics for evaluating a clasification model.\n",
    "\n",
    "Accuracy (overall): \n",
    "        \n",
    "        = TP + TN/(TP + TN + FP + FN)\n",
    "\n",
    "Precision (vertical): \n",
    "        \n",
    "        = TP/(TP + FP) -- how precisely your model identifies sick patients ( positive class)\n",
    "\n",
    "        = TN/ (TN + FN) -- how precisely your model identifies healthy people (negative class)\n",
    "\n",
    "Recall (horizontal direction): \n",
    "        \n",
    "        = TP/ (TP + FN) -- positive class \n",
    "        = TN/ (TN + FP) -- negative class\n",
    "\n",
    "F1 Score:\n",
    "\n",
    "        = 2 * Recall * Precision / Recall + Precision\n",
    "        \n",
    "There will be times when the precision and recall will not make sense for the problem so F1 score is used. It is the mean of the precision and recall. The F1 score tells you how well your model prediction is. It combines precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Confusion matrix - classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiction report for the test data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.93      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('Classifiction report for the test data:')\n",
    "print(classification_report(y_test, y_test_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get the precision, recall, and f1-score for the 3 classes\n",
    "Accuracy of 1 means that the model is correclty predicting all the classes\n",
    "'support' tells us how many records were used to compute the values of precision, recall, and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the object\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# model\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for test data:\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# evaluate the prediction\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Accuracy score for test data:')\n",
    "print(metrics.accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Decision Tree \n",
    "\n",
    "Decision tree is a classification algorithm which tried to make tree like structure using our features in which the internal node represents the test on an attribute.\n",
    "\n",
    "- Each __branch__ represents the outcome of the test\n",
    "- Each __leaf__ node represents the class label\n",
    "- A __path__ from the root to leaf represents classification rules\n",
    "\n",
    "You have the \n",
    "Root node --> Decision node or Terminal node\n",
    "\n",
    "-- Decision node --> Terminal node\n",
    "\n",
    "#### Decision Tree Formation\n",
    "1. __Entropy__ - measures the _impurity_ of a collection of examples i.e. how much are the features not able to express the target\n",
    "2. __Information Gain__ - is the expected reduction in entropy caused by partitioning the examples on an attribute i.e. how well the features predicts the target\n",
    "\n",
    "Entropy and Information gain are inversely proportional to each other.\n",
    "\n",
    "Information gain keeps increasing as it moves to a terminal node while entopy keeps decreasing as it moves to a terminal node\n",
    "\n",
    "Information Gain - Increases towards terminal node\n",
    "\n",
    "Entropy - Decreases towards terminal node\n",
    "\n",
    "#### One main disadvantage of decision tree is __overfitting__\n",
    "So to overcome this limitation, we use __pruning__ to limit the max depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the horse dataset, predict if the horse lived, died, or was euthanized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>mucous_membrane</th>\n",
       "      <th>capillary_refill_time</th>\n",
       "      <th>...</th>\n",
       "      <th>packed_cell_volume</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_appearance</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>outcome</th>\n",
       "      <th>surgical_lesion</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "      <th>cp_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>530101</td>\n",
       "      <td>38.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>died</td>\n",
       "      <td>no</td>\n",
       "      <td>11300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>534817</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pale_cyanotic</td>\n",
       "      <td>less_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>2.0</td>\n",
       "      <td>euthanized</td>\n",
       "      <td>no</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>530334</td>\n",
       "      <td>38.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>less_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lived</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>young</td>\n",
       "      <td>5290409</td>\n",
       "      <td>39.1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>cold</td>\n",
       "      <td>normal</td>\n",
       "      <td>dark_cyanotic</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>5.3</td>\n",
       "      <td>died</td>\n",
       "      <td>yes</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>530255</td>\n",
       "      <td>37.3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dark_cyanotic</td>\n",
       "      <td>more_3_sec</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>died</td>\n",
       "      <td>no</td>\n",
       "      <td>4300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  surgery    age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0      no  adult           530101         38.5   66.0              28.0   \n",
       "1     yes  adult           534817         39.2   88.0              20.0   \n",
       "2      no  adult           530334         38.3   40.0              24.0   \n",
       "3     yes  young          5290409         39.1  164.0              84.0   \n",
       "4      no  adult           530255         37.3  104.0              35.0   \n",
       "\n",
       "  temp_of_extremities peripheral_pulse mucous_membrane capillary_refill_time  \\\n",
       "0                cool          reduced             NaN            more_3_sec   \n",
       "1                 NaN              NaN   pale_cyanotic            less_3_sec   \n",
       "2              normal           normal       pale_pink            less_3_sec   \n",
       "3                cold           normal   dark_cyanotic            more_3_sec   \n",
       "4                 NaN              NaN   dark_cyanotic            more_3_sec   \n",
       "\n",
       "   ... packed_cell_volume total_protein abdomo_appearance abdomo_protein  \\\n",
       "0  ...               45.0           8.4               NaN            NaN   \n",
       "1  ...               50.0          85.0            cloudy            2.0   \n",
       "2  ...               33.0           6.7               NaN            NaN   \n",
       "3  ...               48.0           7.2     serosanguious            5.3   \n",
       "4  ...               74.0           7.4               NaN            NaN   \n",
       "\n",
       "      outcome  surgical_lesion lesion_1 lesion_2  lesion_3  cp_data  \n",
       "0        died               no    11300        0         0       no  \n",
       "1  euthanized               no     2208        0         0       no  \n",
       "2       lived               no        0        0         0      yes  \n",
       "3        died              yes     2208        0         0      yes  \n",
       "4        died               no     4300        0         0       no  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse_df = pd.read_csv('horse.csv')\n",
    "horse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape\n",
    "horse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['surgery', 'age', 'hospital_number', 'rectal_temp', 'pulse',\n",
       "       'respiratory_rate', 'temp_of_extremities', 'peripheral_pulse',\n",
       "       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n",
       "       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux',\n",
       "       'nasogastric_reflux_ph', 'rectal_exam_feces', 'abdomen',\n",
       "       'packed_cell_volume', 'total_protein', 'abdomo_appearance',\n",
       "       'abdomo_protein', 'outcome', 'surgical_lesion', 'lesion_1', 'lesion_2',\n",
       "       'lesion_3', 'cp_data'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check column names\n",
    "horse_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surgery                   object\n",
       "age                       object\n",
       "hospital_number            int64\n",
       "rectal_temp              float64\n",
       "pulse                    float64\n",
       "respiratory_rate         float64\n",
       "temp_of_extremities       object\n",
       "peripheral_pulse          object\n",
       "mucous_membrane           object\n",
       "capillary_refill_time     object\n",
       "pain                      object\n",
       "peristalsis               object\n",
       "abdominal_distention      object\n",
       "nasogastric_tube          object\n",
       "nasogastric_reflux        object\n",
       "nasogastric_reflux_ph    float64\n",
       "rectal_exam_feces         object\n",
       "abdomen                   object\n",
       "packed_cell_volume       float64\n",
       "total_protein            float64\n",
       "abdomo_appearance         object\n",
       "abdomo_protein           float64\n",
       "outcome                   object\n",
       "surgical_lesion           object\n",
       "lesion_1                   int64\n",
       "lesion_2                   int64\n",
       "lesion_3                   int64\n",
       "cp_data                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data types to know what you are working with\n",
    "horse_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'euthanized', 'lived'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the independent variable classes\n",
    "horse_df.outcome.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29536d58688>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check the number of observations/records in the target classes\n",
    "horse_df.outcome.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from above, the lived class is significantly more than say euthanized so the model may tend to be biased towards returning 'lived' when the class should be 'euthanized' so you need to \n",
    "\n",
    "1. collect data that are about same records for all target classes when or\n",
    "2. the 'died' and 'euthanized' classes need to be __over sampled__ <- Read up on how to do this\n",
    "\n",
    "NOte: undersampling can be used if you want to reduce the accuracy by reducing the number of observations sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the independent variables\n",
    "\n",
    "Using some of the independent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 56)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_variables = ['surgery', 'age', 'temp_of_extremities','peripheral_pulse',\n",
    "       'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis',\n",
    "       'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces',\n",
    "     'abdomen','abdomo_appearance', 'surgical_lesion','cp_data']\n",
    "\n",
    "# perform one hot encoding on various features in my dataset\n",
    "horse_encoded_df = pd.get_dummies(horse_df[category_variables])\n",
    "\n",
    "horse_encoded_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notice that there is now 56 columns from the 28 columns we started with._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform label encoding on the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 0, 2, 0, 1, 2, 2, 2, 1, 1, 2, 2, 0, 0, 2, 2, 1,\n",
       "       1, 0, 2, 2, 0, 0, 2, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 0, 0, 0, 1, 2, 2, 0, 2, 0, 2, 2, 0, 2, 2, 0, 1,\n",
       "       2, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 1, 0,\n",
       "       0, 2, 2, 0, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 1, 2, 2, 2, 1, 2, 0, 0,\n",
       "       2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2,\n",
       "       0, 2, 1, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 1, 0, 2,\n",
       "       2, 2, 0, 1, 2, 2, 1, 2, 0, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "       2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 1, 0, 2, 0,\n",
       "       2, 2, 0, 2, 0, 2, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 0, 2, 2, 2, 0, 2,\n",
       "       1, 2, 2, 2, 2, 0, 2, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 2, 2, 2, 1,\n",
       "       2, 2, 2, 2, 0, 0, 1, 2, 1, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(horse_df['outcome'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            died\n",
       "1      euthanized\n",
       "2           lived\n",
       "3            died\n",
       "4            died\n",
       "          ...    \n",
       "294    euthanized\n",
       "295    euthanized\n",
       "296          died\n",
       "297         lived\n",
       "298    euthanized\n",
       "Name: outcome, Length: 299, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse_df['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice from the 2 cells above that died has been assigned as 0, euthanized as 1, lived as 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 56)\n",
      "(239,)\n",
      "(60, 56)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(horse_encoded_df, y, test_size=0.2, random_state=21)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model = DecisionTreeClassifier()  # instantiating the estimator object\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_predict = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy of the Decision Tree model on testing data is: 0.6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_predict, y_test)\n",
    "print('The prediction accuracy of the Decision Tree model on testing data is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy of the Decision Tree model on training data is: 0.99581589958159\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = dt_model.predict(X_train)\n",
    "accuracy = accuracy_score(y_pred_train, y_train)\n",
    "print('The prediction accuracy of the Decision Tree model on training data is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the accuracy of the train data is 99.58% while that of the testing datset is 64.33%. This is a typical case of __overfitting__ and to fix this, we need to prune the tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the decision tree to avoid overfitting\n",
    "\n",
    "To prune, specify the max_depth when initializing the estimator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the estimator object \n",
    "dt_prune = DecisionTreeClassifier(max_depth=4) \n",
    "dt_prune.fit(X_train,y_train)\n",
    "y_predict = dt_prune.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prediction accuracy of the Decision Tree model on testing data is:  0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_predict,y_test)\n",
    "print(\"The Prediction accuracy of the Decision Tree model on testing data is: \" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Prediction accuracy of the Decision Tree model on training data is:  0.7447698744769874\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = dt_prune.predict(X_train)\n",
    "accuracy = accuracy_score(y_pred_train,y_train)\n",
    "print(\"The Prediction accuracy of the Decision Tree model on training data is: \" , accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the accuracy for both trees reduced but the difference is no longer as much as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Decision Tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
