{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "Supervised learning is a type of machine learning used to train models from __labeled training data__. It allows you to presict output for future or unseen data.\n",
    "\n",
    "The 2 types of supervised learning are \n",
    "1. Regression\n",
    "2. Classification\n",
    "\n",
    "## 1. Regression - used when target variable is continuous numeric \n",
    "e.g. prediction of house prices, stock prices, height of a person, salary\n",
    "\n",
    "__Algorithms:__\n",
    "\n",
    "1. Simple Linear\n",
    "2. Multiple Linear\n",
    "3. Polynomial \n",
    "4. Ridge Regression\n",
    "5. Lasso Regression\n",
    "6. ElasticNet Regression\n",
    "\n",
    "## 2. Classification - used when target variable is of categorical type\n",
    "e.g. a transaction is fraudulent or not, patient is diabetic or not, spam/not spam email (2 classes are possible), grades of a student (6 classes from A - F) are possible, movie ratings, classify a trip as long/medium/short distance.\n",
    "Note: the number of classes can be any number based on the possible scenarios\n",
    "\n",
    "__Algorithms:__\n",
    "1. Logistic Regression\n",
    "2. Decision trees\n",
    "3. Support Vector Machines etc.\n",
    "\n",
    "### Examples of supervised learning\n",
    "1. Weather apps used to predict weather at a given time based on prior knowledge of weather over a perios of time for a particular place.\n",
    "\n",
    "2. Email filters into inbox(normal/ham) or junk folder(spam) based on past information od spam\n",
    "\n",
    "3. Netflix/Amazon recommendations - uses what you like and what similar people that likes the movie you liked also liked\n",
    "\n",
    "Note: A model cannot have more than ONE target/output feature\n",
    "\n",
    "\n",
    "classification predict/identifies the class variable while categorization organizes data\n",
    "\n",
    "Grouping - clustering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable types\n",
    "\n",
    "### Quantitative variables            \n",
    "\n",
    "- continuous (float)              \n",
    "- discrete (integer # of kids )   \n",
    "                                 \n",
    "                                                                  \n",
    "### Qualiitative variables\n",
    "- categorical - nominal or ordinal and binary\n",
    "- nominal - no order required\n",
    "- binary - true or false, yes or no\n",
    "- ordinal - tall>medium>short\n",
    "\n",
    "When the target feature is quantitative, you go for regression\n",
    "When the target is qualitative, you go for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning model building steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the right kind of data according to the problem statement.\n",
    "2. Explore your data and visualize the data to gain insight about the data(shape, describe, boxplot, graphs, info, etc).\n",
    "3. Find the relationship between the features and the target i.e. how they are related.\n",
    "4. Encode all the necessay categorial variables present in the dataset. __MACHINE LEARNING CANNOT DEAL WITH OBJECT TYPE DATA. IT CAN ONLY WORK WITH NUMERIC TYPE DATA SO YOU NEED TO ENCODE THE CATEGORICAL DATA. i.e. CONVERT THEM TO NUMERIC TYPE. The process is called ENCODING.__\n",
    "5. Identify the target variable and split the features into X(features) and y(target) i.e. isolate/remove your target variable from the features.\n",
    "6. Split the original dataaset into train set and test set e.g. 80:20 or 70:30 etc (industry dependent) where 80%-training set and 20%-testing set\n",
    "\n",
    "1000 data points - original dataset\n",
    "\n",
    "training - 800 data points\n",
    "testing - 200 data points.\n",
    "7. Build your machine learning model with the training dataset (features, target).\n",
    "8. Test your model with the features of the test dataset and observe the prediction output. You then compare the predicted output and the actual target of the test dataset.\n",
    "9. Use various evaluation metrics for regression and classification to determine how well your model is performing.\n",
    "\n",
    "\n",
    "ETL - Extract, Transform, Load people prep the data for Data Scientists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Regression is the __strength of relationship__ between your features and target variables:\n",
    "\n",
    "__y = mx + c__\n",
    "\n",
    "m = regression coefficient which expresses the strength of relationship between the feature and the target\n",
    "\n",
    "- y = target\n",
    "- x = feature\n",
    "- m = slope\n",
    "- c = intercept\n",
    "\n",
    "### 1. Simple linear regression:\n",
    "For simple linear regression, you have one target variable and ONLY one feature\n",
    "\n",
    "### 2. Multiple linear regression\n",
    "You have more than one feature\n",
    "\n",
    "__y = b1x1 + b2x2 + b3x3 +.......+ bnxn + c__\n",
    "\n",
    "where b1, b2, b3, ...,bn are regression coefficients which express the strength of the relationship between x1, x2, x3...,xn respectively with y.\n",
    "\n",
    "#### Evaluation metrics for regression\n",
    "        Root Mean Squared error - root of squared mean error (where error = actual-predicted)\n",
    "        R2 Score - how the model fits the data\n",
    "        \n",
    "### 3. Polynomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using one of the 7 datasets inbuilt in sklearn\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()  # instantiate it and assign it to a variable\n",
    "\n",
    "# this is not a dataframe but a Bunch- sklearrn data type\n",
    "type(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the features in the dataset\n",
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the documentation for the dataset\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2    3      4      5     6       7    8      9    10  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
       "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
       "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
       "\n",
       "         11    12  \n",
       "0    396.90  4.98  \n",
       "1    396.90  9.14  \n",
       "2    392.83  4.03  \n",
       "3    394.63  2.94  \n",
       "4    396.90  5.33  \n",
       "..      ...   ...  \n",
       "501  391.99  9.67  \n",
       "502  396.90  9.08  \n",
       "503  396.90  5.64  \n",
       "504  393.45  6.48  \n",
       "505  396.90  7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember that it's not a dataframe yet so first convert it to a dataframe\n",
    "# boston data is an array under data\n",
    "import pandas as pd\n",
    "boston_df = pd.DataFrame(boston.data, )\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are no column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "boston_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output/target MEDV is not included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column MEDV and assign the target data to it\n",
    "boston_df['MEDV'] = boston.target\n",
    "\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM     ZN  INDUS   CHAS    NOX     RM    AGE    DIS    RAD    TAX  \\\n",
       "0    False  False  False  False  False  False  False  False  False  False   \n",
       "1    False  False  False  False  False  False  False  False  False  False   \n",
       "2    False  False  False  False  False  False  False  False  False  False   \n",
       "3    False  False  False  False  False  False  False  False  False  False   \n",
       "4    False  False  False  False  False  False  False  False  False  False   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "501  False  False  False  False  False  False  False  False  False  False   \n",
       "502  False  False  False  False  False  False  False  False  False  False   \n",
       "503  False  False  False  False  False  False  False  False  False  False   \n",
       "504  False  False  False  False  False  False  False  False  False  False   \n",
       "505  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "     PTRATIO      B  LSTAT   MEDV  \n",
       "0      False  False  False  False  \n",
       "1      False  False  False  False  \n",
       "2      False  False  False  False  \n",
       "3      False  False  False  False  \n",
       "4      False  False  False  False  \n",
       "..       ...    ...    ...    ...  \n",
       "501    False  False  False  False  \n",
       "502    False  False  False  False  \n",
       "503    False  False  False  False  \n",
       "504    False  False  False  False  \n",
       "505    False  False  False  False  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values - you'll get True if there is a null value and false if it isn't null\n",
    "boston_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .sum() after .isnull() to add up the true and false values. It will show the number of null values for each feature. 0 means there is no null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "boston_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting your X and y\n",
    "\n",
    "X - variable which holds all the features\n",
    "\n",
    "y - variable which holds the target value\n",
    "\n",
    "Here you have the liberty to either use the Bunch data type which has separate X(feature) and y(target) already or to drop the target and assign the features to X and target to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Using the data from sklearn in bunch format - with separate feature and target values already\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: splitting X and y from the dataframe which has features and target\n",
    "X = boston_df.drop('MEDV', axis=1)  # 1 for column\n",
    "y = boston_df['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoke the split method, it will return 4 values which is assigned to variables X train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# test size (0,1):\n",
    "# 0 denotes that the entire data has been used for training\n",
    "# 1 denotes that the entire data has been used for testing\n",
    "# 0.2 - 20% of data is taken for testing\n",
    "# 0.3 - 30% of data is taken for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of your split to confirm it's 80:20\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept for the LR model is: 40.69881135855521\n",
      "The coefficient for all the features: [-1.27264773e-01  5.60695259e-02  4.65903493e-02  1.75069088e+00\n",
      " -1.92558353e+01  3.57749108e+00 -7.10009639e-03 -1.55175123e+00\n",
      "  3.16634503e-01 -1.21701176e-02 -1.03792319e+00  9.05514554e-03\n",
      " -5.10400467e-01]\n"
     ]
    }
   ],
   "source": [
    "#1. import the necessary model function\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#2. instantiate the estimator object\n",
    "model_lr = LinearRegression()\n",
    "\n",
    "#3. fit the model on the data i.e. training the model with the data - supervised approach\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "print('The intercept for the LR model is:', model_lr.intercept_)\n",
    "print('The coefficient for all the features:', model_lr.coef_)  # there will be 13 values i.e. 1 value for each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that without setting the __random state__, i.e. a seed you will get different values each time you run the model because of the random selection of the records during split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept for the LR model is: 40.653176529790514\n",
      "The coefficient for all the features: [-8.77422649e-02  4.87770336e-02  1.94746142e-02  3.06314365e+00\n",
      " -1.84821160e+01  3.34704170e+00  3.22024333e-03 -1.42569490e+00\n",
      "  3.25184188e-01 -1.20259158e-02 -1.05582832e+00  1.07682087e-02\n",
      " -5.38356500e-01]\n"
     ]
    }
   ],
   "source": [
    "# set the seed to 21, can be any integer value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "print('The intercept for the LR model is:', model_lr.intercept_)\n",
    "print('The coefficient for all the features:', model_lr.coef_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6a. __RMSE__ is used for evaluating regression\n",
    "\n",
    "error = actual - predicted\n",
    "\n",
    "when actual > predicted, +ve error value\n",
    "when actual < predicted, -ve error value\n",
    "\n",
    "so RMSE is the root of the mean of all squared errors. Squared to take care of -ve values before averaging/mean and root to return it back to previous magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model - use the same estimator object and the predict function\n",
    "# Use only your X_test so your model can come up with the predicted target values\n",
    "y_pred = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual y_test</th>\n",
       "      <th>Predicted y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>14.1</td>\n",
       "      <td>15.311568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>13.4</td>\n",
       "      <td>15.324187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>22.1</td>\n",
       "      <td>26.890855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>41.7</td>\n",
       "      <td>37.384876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>28.5</td>\n",
       "      <td>33.375220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>19.1</td>\n",
       "      <td>20.027912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>19.1</td>\n",
       "      <td>17.513802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>26.4</td>\n",
       "      <td>29.172278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>17.6</td>\n",
       "      <td>16.904621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>23.1</td>\n",
       "      <td>24.767296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual y_test  Predicted y_test\n",
       "455           14.1         15.311568\n",
       "142           13.4         15.324187\n",
       "311           22.1         26.890855\n",
       "232           41.7         37.384876\n",
       "290           28.5         33.375220\n",
       "..             ...               ...\n",
       "486           19.1         20.027912\n",
       "468           19.1         17.513802\n",
       "302           26.4         29.172278\n",
       "244           17.6         16.904621\n",
       "321           23.1         24.767296\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare your predicted value (y_pred) with the y_test values\n",
    "# we want to show the values side by side so create a dataframe with values in a dict\n",
    "pd.DataFrame({'Actual y_test': y_test, 'Predicted y_test':y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there is a deviation in the actual and predicted values so to find the RMSE, import numpy to be able to use the sqrt function. We only get mean_squared_error from sklearn but this is ROOT mean squared error so Numpy will provide the ROOT part which sklearn doesn't.\n",
    "\n",
    "The mean_sqaured_error function will only accept 2 values (in this case, the actual and pred variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of testing dataset\n",
      "5.179324335658004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print('RMSE value of testing dataset')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE tells us that overall there is an average deviation of 5.18\n",
    "Remember that our y i.e MEDV is in 1000 dollars i.e. x1k. So the RMSE value acceptance is dependent on the problem statement. This may be ok depending on the context/ what y target represents. A +/-$5.17K difference in the house price in this case may be considered acceptable in the real estate field. \n",
    "\n",
    "If the RMSE value is too high, it means the model is not good enough. You can try another model type e.g. polynomial or select the features that are best correlated\n",
    "\n",
    "Note: You only use __linear regression__ if there is a linear relationship between the target and features. Use a scatterplot to check the relationship/spread between the features and the target variable.\n",
    "\n",
    "If the spread is non linear, you use polynomial regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the above use of multiple features is Multiple Linear Regression and not Linear Regression. You also need to use the features that are good predictors for the target variable i.e features with the best correlation. Refer to IBM DA0101EN - Data Analysis with Python training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6b. R2 Score\n",
    "__R2 Score__ is also used to determine how well the model fits the data. Use R2 Score to infer how well the model fits the dataset after using the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score is: 0.714936416139223\n"
     ]
    }
   ],
   "source": [
    "# the method is inbuilt in the linear regression function so you don't need to import any new metric\n",
    "\n",
    "print('R2 Score is:', model_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score tells us that our model was able to fit about 71% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recap from Day 2__\n",
    "\n",
    "Adjusted R2 is adjusted to accomodate multi features\n",
    "\n",
    "R2 is also called coefficient of determination. It tells you how the line(model) fits the data points\n",
    "\n",
    "Acceptable RMSE value is problem specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Let's you now the relationship between 2 variables/features. \n",
    "\n",
    "Correlation is used only for __numeric__ values. For categorical values, __Chi Squared test__ is used\n",
    "\n",
    "It ranges from -1 to +1\n",
    "\n",
    "### Types of correlation\n",
    "- Positive correlation\n",
    "- Negative Correlation\n",
    "- No correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression equation \n",
    "For e.g. house price prediction\n",
    "\n",
    "y(house price) = b1(no of bedrooms) + b2(sqft) + c\n",
    "\n",
    "b1 - strength of relationship between the no of rooms and house price column\n",
    "\n",
    "b2 - will tell us the strength of the relationship between the sqfootage and house price column\n",
    "\n",
    "The assumption in regression is that the independent variables are independent of each other which in actual fact is incorrect.\n",
    "\n",
    "- Positive correlation - Direct variation - when the value of one variable increases, the value of the other variable also increases\n",
    "\n",
    "- Negative Correlation - Indirect variation - when the value of one variable increases, the value of the other variable decreases\n",
    "\n",
    "Strong +ve correlation values = 0.8 to 1\n",
    "Strong -ve correlation values = -0.8 to -1\n",
    "\n",
    "\n",
    "### Factor Analysis\n",
    "If two independent variables are correlated, one of them will be dropped to avoid multicolinearity. If it's not removed, it will miscalculate the values for b1, b2 i.e. the regression coefficients will be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to check the correlation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEDV</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "MEDV    -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "              DIS       RAD       TAX   PTRATIO         B     LSTAT      MEDV  \n",
       "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "MEDV     0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make inferences from the correlation\n",
    "\n",
    "INDUS & DIS columns have a strong negative correlation\n",
    "INDUS & NOX have a strong positive correlation\n",
    "INDUX & TAX have a strong positive correlation\n",
    "AGE & DIS have a strong negative correlation\n",
    "AGE & NOX have a strong positive correlation\n",
    "RAD & TAX have the strongest positive correlation = 0.9\n",
    "DIS & NOX have a strong negative correlation\n",
    "\n",
    "#### eliminate columns by checking which correlates most with other columns\n",
    "Based on this correlation analysus, we will eliminate INDUS, DIS, RAD\n",
    "\n",
    "#### Note: the elimination has nothing with how they correlate with your dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "(506, 11)\n"
     ]
    }
   ],
   "source": [
    "correlated_cols = ['INDUS','RAD', 'DIS']\n",
    "\n",
    "# drop them from the dataset\n",
    "boston_df_new = boston_df.drop(correlated_cols, axis=1)\n",
    "\n",
    "print(boston_df.shape)\n",
    "print(boston_df_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the 3 columns have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 10)\n"
     ]
    }
   ],
   "source": [
    "# drop the target/dependent variable from X data and assign it to y data\n",
    "X_new = boston_df_new.drop('MEDV', axis=1)\n",
    "y_new = boston_df_new['MEDV']\n",
    "\n",
    "print(X_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 10)\n",
      "(404,)\n",
      "(102, 10)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=21)\n",
    "\n",
    "# check \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the type of model you want to use\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "model_lr_new = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model_lr_new.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred_new = model_lr_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.50672864900264\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_new)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the regression model by changing the hyperparameters, tab + double shift inside the parenthesis where you instantiate the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.415684304197959\n"
     ]
    }
   ],
   "source": [
    "# import the type of model you want to use\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate the model\n",
    "model_lr_new = LinearRegression(fit_intercept=False)  # fit_intercept default value is True. Turn it to False to see if the accuracy will improve.\n",
    "\n",
    "# fit the model\n",
    "model_lr_new.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_new = model_lr_new.predict(X_test)\n",
    "\n",
    "# check accuracy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Notice that the RMSE value decreased i.e. slightly improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way to visualize the correlation \n",
    "\n",
    "When presenting to a client or non tech audience, a heatmap can be used instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1eb829fd4c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(boston_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges in Prediction\n",
    "\n",
    "1. Under Fit - Will not work well on test data. Retraining may be needed to find a better fit.\n",
    "2. Appropriate Fit\n",
    "3. Over Fit - model will work really well on training data but won't not be able to perform well with test/new unseen data\n",
    "\n",
    "__How do you identify if a model is working well for your data or not?__\n",
    "\n",
    "Solution: Compare the RMSE values for both the test and train data. \n",
    "\n",
    "- __Underfitting__ - If the RMSE values are __very high__, then it implies under fitting i.e. the model is under fit and will not model the data properly\n",
    "\n",
    "- For __Overfitting__, the value of the RMSE for the training data will be much __less than__ the RMSE for the testing data\n",
    "\n",
    "- If the model is an __appropriate model__, the RMSE value of both the train data and the test data will be less and __almost equal__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is also called the dependent variable\n",
    "\n",
    "Features are also called independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 3 remaining types of regression - Ridge (aka L2 regularization). Lasso, and ElasticNet are called regularized regression algorithms because they have regularization terms in them to avoid overfitting, multicollinearity (correlation between independent features).\n",
    "\n",
    "Other types of regression are: Linear, Multiple and Polynomial regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression (L2) is used when there is a problem of multicollinearity or you want to reduce the prediction error e.g. Reducing the RMSE from 5k dollars in our house price prediction in linear regression to say 4k.\n",
    "\n",
    "By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors i.e. it shifts the predicted line to reduce the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Minimization object = LS object + Lambda*(sum of the square of coefficients)__\n",
    "\n",
    "where: \n",
    "LS object refers to least squares objective\n",
    "Lambda controls the strength of the penalty term \n",
    "Default Lambda value is 1\n",
    "penalty term = b1^2 + b2^ +....+bn^2 i.e how much you want to penalize your regression model for not predicting correctly\n",
    "\n",
    "Lambda is a hyperparameter so you need to try different lambda values to see which is the best. Grid search cv is a good technique to determine the best/optimal hyperparameter value to use. Note that there is a limit to the bias to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Lasso Regression/L1 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression(L1) is similar to ridge, but it also performs feature selection.\n",
    "\n",
    "It will set the coefficient value for features that do not help in decision making very low, potentially zero.\n",
    "\n",
    "__Minimization object = LS obj + Lambda*(sum of absolute coefficient values)__\n",
    "\n",
    "i.e. LS obj + lambda*(|b1| + |b2| + |b3| +.......+|bn|)\n",
    "\n",
    "Lasso regression tends to exclude  variables that are not required from the equation, where as Ridge tends to do better when all variables are present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet regression combines the strength of ridge and lasso regression.\n",
    "\n",
    "lambda1*|variable1| +....+|variablex| __+__ lambda2 * variable1^2 +...+variablex^2\n",
    "\n",
    "where:\n",
    "\n",
    "- lambda1*|variable1| +....+|variablex| is lasso penalty\n",
    "\n",
    "- lambda2 * variable1^2 +...+variablex^2 is ridge penalty\n",
    "\n",
    "__If you are not sure whether to use lasso or ridge, use ElasticNet__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.415663321107286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# ridge_reg = Ridge()\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.02, fit_intercept=False)  # default lambda(alpha) value = 1.0\n",
    "\n",
    "# fit the data\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_test_pred = ridge_reg.predict(X_test)\n",
    "\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the train and test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.026821360422799\n"
     ]
    }
   ],
   "source": [
    "# predict with the training dataset\n",
    "y_train_pred = ridge_reg.predict(X_train)\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training RMSE and the tesing RMSE values are almost equal and within permissable RMSE value limits for the given problem statment, this model is an __appropriate model__ for the boston dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso()\n",
    "\n",
    "lasso_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "6.037132064354421\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's high so let's see if we can reduce the RMSE with an alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.49617389164474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.02)\n",
    "\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = lasso_reg.predict(X_test)\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ElasticNet regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.03, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_reg = ElasticNet(alpha=0.03)   #l1_ratio idle values 0.2-0.6. tab + double shift\n",
    "\n",
    "elastic_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value of the testing dataset is:\n",
      "5.507835456325728\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = elastic_reg.predict(X_test)\n",
    "\n",
    "print('RMSE value of the testing dataset is:')\n",
    "print(np.sqrt(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
